{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock market one-day ahead movement prediction using disparate data sources\n",
    "There are several commercial financial expert systems that can be used for trading on the stock exchange. However, their predictions are somewhat limited since they primarily rely on time-series analysis of the market. With the rise of the Internet, new forms of collective intelligence (e.g. Google and Wikipedia) have emerged, representing a new generation of “crowd-sourced”knowledge bases. They collate infor- mation on publicly traded companies, while capturing web traffic statistics that reflect the public’s collective interest. Google and Wikipedia have become important “knowledge bases”for investors. In this research, we hypothesize that combining disparate online data sources with traditional time-series and technical indicators for a stock can provide a more effective and intelligent daily trading expert system.  machine learning models like support vector machines, serve as the basis for our “inference engine”. To evaluate the performance of our expert system, we present a case study based on the AAPL (Apple NASDAQ) stock. Our expert system had an 85% accuracy in predicting the next-day AMZN stock movement, which outperforms the reported rates in the literature. Our results suggest that: (a) the knowledge base of financial expert systems can benefit from data captured from nontraditional “experts”like Google and Wikipedia; (b) diversifying the knowledge base by combining data from disparate sources can help improve the performance of financial expert systems; and (c) the use of simple machine learning models for inference and rule generation is appropriate with our rich knowledge database. Finally, an intelligent decision making tool is provided to assist investors in making trading decisions on any stock, commodity or index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. TRUE\n",
       "2. TRUE\n",
       "3. TRUE\n",
       "4. TRUE\n",
       "5. TRUE\n",
       "6. TRUE\n",
       "7. TRUE\n",
       "8. TRUE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] TRUE\n",
       "\n",
       "[[2]]\n",
       "[1] TRUE\n",
       "\n",
       "[[3]]\n",
       "[1] TRUE\n",
       "\n",
       "[[4]]\n",
       "[1] TRUE\n",
       "\n",
       "[[5]]\n",
       "[1] TRUE\n",
       "\n",
       "[[6]]\n",
       "[1] TRUE\n",
       "\n",
       "[[7]]\n",
       "[1] TRUE\n",
       "\n",
       "[[8]]\n",
       "[1] TRUE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>python:</strong> 'C:\\\\Users\\\\MAYANK\\\\ANACON~1\\\\envs\\\\R\\\\python.exe'"
      ],
      "text/latex": [
       "\\textbf{python:} 'C:\\textbackslash{}\\textbackslash{}Users\\textbackslash{}\\textbackslash{}MAYANK\\textbackslash{}\\textbackslash{}ANACON\\textasciitilde{}1\\textbackslash{}\\textbackslash{}envs\\textbackslash{}\\textbackslash{}R\\textbackslash{}\\textbackslash{}python.exe'"
      ],
      "text/markdown": [
       "**python:** 'C:\\\\Users\\\\MAYANK\\\\ANACON~1\\\\envs\\\\R\\\\python.exe'"
      ],
      "text/plain": [
       "                                            python \n",
       "\"C:\\\\Users\\\\MAYANK\\\\ANACON~1\\\\envs\\\\R\\\\python.exe\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'F:/Games/finproj'"
      ],
      "text/latex": [
       "'F:/Games/finproj'"
      ],
      "text/markdown": [
       "'F:/Games/finproj'"
      ],
      "text/plain": [
       "[1] \"F:/Games/finproj\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#____________________________libraries______________________________________________\n",
    "lib=c(\"quantmod\",\"TTR\",\"wikipediatrend\",\"dplyr\",\"ggplot2\",\"reticulate\",\"readr\",\"e1071\")\n",
    "lapply(lib, require, character.only = TRUE)\n",
    "Sys.which(\"python\")\n",
    "use_python(\"C:\\\\Python27\\\\python.exe\", required = T)\n",
    "setwd(\"F:/Games/finproj\")\n",
    "getwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the input, stock ticker and date range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock <- \"AMZN\"\n",
    "terms <- c(\"Amazon Prime\",\"AWS\",\"Alexa Internet\")\n",
    "date_begin <- \"1/1/2010\"\n",
    "date_end <- \"12/1/2019\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the date format for \"Quantmod\" package\n",
    "date_begin_m <- strptime(as.character(date_begin), \"%m/%d/%Y\")\n",
    "date_end_m <- strptime(as.character(date_end), \"%m/%d/%Y\")\n",
    "# Define the variables that we are going to use\n",
    "\n",
    "Input_vars = c(\"Open\",\"Close\",\"High\",\"Low\",\"Wiki_5day_Disparity\",\"Wiki_Move\",\n",
    "               \"Wiki_MA3_Move\",\"Wiki_EMA5_Move\",\"Wiki_5day_Disparity_Move\",\n",
    "               \"Google_EMA5_Move\",\"Google_3day_Disparity_Move\",\"Google_ROC_Move\",\n",
    "               \"Google_RSI_Move\",\"Wiki_3day_Disparity\",\"Stochastic Oscillator\",\n",
    "               \"RSI Move\",\"Wiki_RSI_Move\",\"Google_MA_6\",\"Google_Move\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull the market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'AMZN'"
      ],
      "text/latex": [
       "'AMZN'"
      ],
      "text/markdown": [
       "'AMZN'"
      ],
      "text/plain": [
       "[1] \"AMZN\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "           AMZN.Open AMZN.High AMZN.Low AMZN.Close AMZN.Volume AMZN.Adjusted\n",
       "2010-01-04    136.25    136.61   133.14     133.90     7599900        133.90\n",
       "2010-01-05    133.43    135.48   131.81     134.69     8851900        134.69\n",
       "2010-01-06    134.60    134.73   131.65     132.25     7178800        132.25\n",
       "2010-01-07    132.01    132.32   128.80     130.00    11030200        130.00\n",
       "2010-01-08    130.56    133.68   129.03     133.52     9830500        133.52\n",
       "2010-01-11    132.62    132.80   129.21     130.31     8779400        130.31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the market data\n",
    "\n",
    "getSymbols(stock, from=date_begin_m, to = date_end_m, src=\"yahoo\")\n",
    "\n",
    "# Create the date list\n",
    "\n",
    "date_market <- data.frame(index(AMZN))   # ??? Change to data frame\n",
    "\n",
    "# Get Open_Price, Close_Price, High_Price, Low_Price\n",
    "\n",
    "\n",
    "data_from_yahoo <- AMZN # ? How to change this using input ???? try noquote(stock), not working\n",
    "adjust_coff <- data_from_yahoo[,4]/data_from_yahoo[,6]  # Get the adjust index\n",
    "Open_Price <- data_from_yahoo[,1]/adjust_coff   # Get the adjusted value based on index, similar below\n",
    "Close_Price <- data_from_yahoo[,6]\n",
    "High_Price <- data_from_yahoo[,2]/adjust_coff\n",
    "Low_Price <- data_from_yahoo[,3]/adjust_coff\n",
    "head(data_from_yahoo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calulate the technical indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Stochastic Oscillator\n",
    "\n",
    "data_for_sto <- data.frame(High_Price,Low_Price,Close_Price,row.names = NULL)\n",
    "colnames(data_for_sto) <- c(\"High\",\"Low\",\"Close\")    #Meet the format of fuction\n",
    "full_sto <- data.frame(stoch(data_for_sto))\n",
    "Stochastic_Oscillator <- full_sto$fastK * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the RSI_Move\n",
    "the_RSI <- RSI(Close_Price)     #Get the RSI\n",
    "RSI_Move <- diff(the_RSI)       #Get the difference as previous day\n",
    "RSI_Move[RSI_Move<0] <- 0       # 0 means going down\n",
    "RSI_Move[RSI_Move>0] <- 1       # 1 means going up\n",
    "RSI_Move <- data.frame(RSI_Move)  # Transfer to data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporary full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t2495 obs. of  7 variables:\n",
      " $ Date                 : Date, format: \"2010-01-04\" \"2010-01-05\" ...\n",
      " $ Open                 : num  136 133 135 132 131 ...\n",
      " $ Close                : num  134 135 132 130 134 ...\n",
      " $ High                 : num  137 135 135 132 134 ...\n",
      " $ Low                  : num  133 132 132 129 129 ...\n",
      " $ Stochastic Oscillator: num  NA NA NA NA NA NA NA NA NA NA ...\n",
      " $ RSI Move             : num  NA NA NA NA NA NA NA NA NA NA ...\n"
     ]
    }
   ],
   "source": [
    "fulldata_temp <- data.frame(date_market,Open_Price,Close_Price,\n",
    "                            High_Price,Low_Price, Stochastic_Oscillator,\n",
    "                            RSI_Move,row.names = NULL)\n",
    "colnames(fulldata_temp) <- c(\"Date\",\"Open\",\"Close\",\"High\",\"Low\",\"Stochastic Oscillator\",\n",
    "                             \"RSI Move\")\n",
    "\n",
    "str(fulldata_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in eval(expr, envir, enclos):\n",
      "\"NAs introduced by coercion\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t2495 obs. of  8 variables:\n",
      " $ Date                 : Date, format: \"2010-01-04\" \"2010-01-05\" ...\n",
      " $ Open                 : num  136 133 135 132 131 ...\n",
      " $ Close                : num  134 135 132 130 134 ...\n",
      " $ High                 : num  137 135 135 132 134 ...\n",
      " $ Low                  : num  133 132 132 129 129 ...\n",
      " $ Stochastic Oscillator: num  NA NA NA NA NA NA NA NA NA NA ...\n",
      " $ RSI Move             : num  NA NA NA NA NA NA NA NA NA NA ...\n",
      " $ Target               : num  0 1 0 0 1 0 0 1 1 0 ...\n"
     ]
    }
   ],
   "source": [
    "# Based on Target 2: O(i+1) - O(i)\n",
    "\n",
    "Target <- diff(Open_Price)\n",
    "Target_temp <- Target[2:length(Target),]\n",
    "Target <- rbind.data.frame(Target_temp,\"NA\")\n",
    "names(Target) <- c(\"Target\")\n",
    "Target=as.numeric(Target$Target)\n",
    "Target[Target<0] <- 0       # 0 means going down\n",
    "Target[Target>0] <- 1       # 1 means going up\n",
    "Target <- data.frame(Target)  # Transfer to data frame\n",
    "fulldata_temp <- cbind(fulldata_temp,Target)\n",
    "str(fulldata_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull the Wikipedia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1\n",
      "[1] 1\n"
     ]
    }
   ],
   "source": [
    "# Get Wikipeida data                    Start from here\n",
    "Wiki_traffic_ALL <- wp_trend(page = c(stock,terms),\n",
    "                             from = date_begin_m,\n",
    "                             to= date_end_m)          # Pull the data based on pre-defined terms\n",
    "term_count <- length(terms) +1\n",
    "\n",
    "# and stock ticker\n",
    "while(nrow(Wiki_traffic_ALL) %% term_count != 0) {\n",
    "  print(1)\n",
    "  Wiki_traffic_ALL=Wiki_traffic_ALL[-1,]\n",
    "  }\n",
    "#############\n",
    "Wiki_traffic <- colSums(matrix(Wiki_traffic_ALL$views, nrow = term_count)) # Take the sum by each day for all search terms\n",
    "Wiki_traffic_ALL$date <- as.Date(Wiki_traffic_ALL$date)\n",
    "Wiki_traffic_date <- colSums(matrix(Wiki_traffic_ALL$date, nrow = term_count)/term_count) # Collect related date. To check the\n",
    "# date, use as.Date()\n",
    "Wiki_traffic_date=as.Date(Wiki_traffic_date)\n",
    "Wiki_traffic_with_date <- data.frame(Wiki_traffic_date,Wiki_traffic)  # Combine the data\n",
    "date_market_compare <- data.matrix(date_market)  # Tranfer from list to double for comparsion\n",
    "date_market_compare = as.Date(date_market_compare)\n",
    "#Compare the seq date with market open date\n",
    "date_diff_wiki <- setdiff(Wiki_traffic_with_date$Wiki_traffic_date,date_market_compare) \n",
    "date_diff_wiki=as.Date(date_diff_wiki)\n",
    "#Only keep the dates when market opens\n",
    "Wiki_traffic_with_date_new <- Wiki_traffic_with_date[!Wiki_traffic_with_date$Wiki_traffic_date %in% date_diff_wiki,]\n",
    "#This is the limitation, pull wiki traffic data might miss some data point\n",
    "miss_wiki <- setdiff(date_market_compare,Wiki_traffic_with_date_new$Wiki_traffic_date)\n",
    "miss_wiki=as.Date(miss_wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate moving average of wiki traffic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Wiki_Move\n",
    "Wiki_traffic_market <- data.frame(Wiki_traffic_with_date_new$Wiki_traffic)\n",
    "\n",
    "Wiki_Move <- diff(Wiki_traffic_with_date_new$Wiki_traffic)  #Get the difference as previous day\n",
    "Wiki_Move[Wiki_Move<0] <- 0       # 0 means going down\n",
    "Wiki_Move[Wiki_Move>0] <- 1       # 1 means going up\n",
    "Wiki_Move <- data.frame(Wiki_Move) # Transfer to data frame\n",
    "Wiki_Move <- rbind(\"N/A\",Wiki_Move) # Move down for one row\n",
    "\n",
    "\n",
    "# Calulate Wiki_MA3_Move, Wiki_EMA5_Move, Wiki_RSI_Move\n",
    "Wiki_MA_3 <- SMA(Wiki_traffic_market, 3)  # 3 day Moving average of Wiki Traffic\n",
    "Wiki_EMA_5 <- EMA(Wiki_traffic_market, 5) # 5 day Exponential moving average of Wiki Traffic\n",
    "Wiki_RSI <- RSI(Wiki_traffic_market, maType = \"WMA\") # RSI of wiki traffic\n",
    "\n",
    "Wiki_MA3_Move <-diff(Wiki_MA_3)\n",
    "Wiki_MA3_Move[Wiki_MA3_Move<0] <- 0       # 0 means going down\n",
    "Wiki_MA3_Move[Wiki_MA3_Move>0] <- 1       # 1 means going up\n",
    "Wiki_MA3_Move <- data.frame(Wiki_MA3_Move)\n",
    "Wiki_MA3_Move <- rbind(\"N/A\",Wiki_MA3_Move) # Move down for one row\n",
    "\n",
    "Wiki_EMA5_Move <- diff(Wiki_EMA_5)\n",
    "Wiki_EMA5_Move[Wiki_EMA5_Move<0] <- 0       # 0 means going down\n",
    "Wiki_EMA5_Move[Wiki_EMA5_Move>0] <- 1       # 1 means going up\n",
    "Wiki_EMA5_Move <- data.frame(Wiki_EMA5_Move)\n",
    "Wiki_EMA5_Move <- rbind(\"N/A\",Wiki_EMA5_Move) # Move down for one row\n",
    "\n",
    "Wiki_RSI_Move <- diff(Wiki_RSI)\n",
    "Wiki_RSI_Move[Wiki_RSI_Move<0] <- 0       # 0 means going down\n",
    "Wiki_RSI_Move[Wiki_RSI_Move>0] <- 1       # 1 means going up\n",
    "Wiki_RSI_Move <- data.frame(Wiki_RSI_Move)\n",
    "Wiki_RSI_Move <- rbind(\"N/A\",Wiki_RSI_Move) # Move down for one row\n",
    "\n",
    "# Calculate Wiki_5day_Disparity, Wiki_5day_Disparity_Move, Wiki_3day_Disparity\n",
    "\n",
    "Wiki_MA_5 <- SMA(Wiki_traffic_market,5)  # 5 day moving average of Wiki Traffic\n",
    "Wiki_3day_Disparity <- Wiki_traffic_market/Wiki_MA_3  #Please refer to Appendix II formula 3 \n",
    "Wiki_5day_Disparity <- Wiki_traffic_market/Wiki_MA_5\n",
    "Wiki_3day_Disparity <- as.numeric(unlist(Wiki_3day_Disparity))\n",
    "Wiki_5day_Disparity <- as.numeric(unlist(Wiki_5day_Disparity))\n",
    "Wiki_5day_Disparity_Move <- diff(Wiki_5day_Disparity)\n",
    "Wiki_5day_Disparity_Move[Wiki_5day_Disparity_Move <0] <- 0       # 0 means going down\n",
    "Wiki_5day_Disparity_Move[Wiki_5day_Disparity_Move >0] <- 1       # 1 means going up\n",
    "Wiki_5day_Disparity_Move <- data.frame(Wiki_5day_Disparity_Move)\n",
    "Wiki_5day_Disparity_Move <- rbind(\"N/A\",Wiki_5day_Disparity_Move) # Move down for one row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporary full data after Wiki date match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with the missing data point after wiki\n",
    "fulldata_temp <- fulldata_temp[!fulldata_temp$Date %in% miss_wiki,]\n",
    "Wiki_data <- data.frame(Wiki_Move,Wiki_MA3_Move,Wiki_EMA5_Move, Wiki_RSI_Move,Wiki_5day_Disparity, \n",
    "                        Wiki_5day_Disparity_Move, Wiki_3day_Disparity)\n",
    "fulldata_temp <- cbind(fulldata_temp,Wiki_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Google Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Google Web Scraping google.py\n",
    "# Function: getNewsCount (term, begDate, endDate) call this function use python.call\n",
    "# python.call(\"getNewsCount\", stock, a[3], date_end)\n",
    " \n",
    "#Load python function\n",
    "source_python(\"F:/Games/finproj/google.py\")\n",
    "\n",
    "date_format_google <- format(fulldata_temp$Date,\"%m/%d/%Y\") #format the date to \"01/01/2013\"\n",
    "#Create a dummy vector of zeros\n",
    "Google_counts <- rep(0,length(date_format_google))\n",
    "str(Google_counts)\n",
    "#Get the google news count by each day\n",
    "for (i in 1:length(date_format_google)) {\n",
    "  Google_counts[i] = getNewsCount(stock, date_format_google[i], date_end)\n",
    "}\n",
    "\n",
    "# Combine the date with google counts to double check the data\n",
    "Google_counts_with_date <- data.frame(fulldata_temp$Date, Google_counts)\n",
    "\n",
    "#Get Google_EMA5_Move\n",
    "Google_counts_market <- as.numeric(gsub(\",\",\"\",Google_counts))   #Dealing with the 1,234 format to 1234\n",
    "\n",
    "Google_counts_market=na.approx(Google_counts_market) #handling 'Series contains non-leading NAs' in TTR library with xts objects?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate moving averages of google traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Google_EMA5_Move\n",
    "\n",
    "Google_EMA_5 <- EMA(Google_counts_market,5)\n",
    "\n",
    "Google_EMA5_Move <- diff(Google_EMA_5)\n",
    "Google_EMA5_Move[Google_EMA5_Move <0] <- 0       # 0 means going down\n",
    "Google_EMA5_Move[Google_EMA5_Move >0] <- 1       # 1 means going up\n",
    "Google_EMA5_Move <- data.frame(Google_EMA5_Move)\n",
    "Google_EMA5_Move <- rbind(\"N/A\",Google_EMA5_Move) # Move down for one row\n",
    "\n",
    "#Get Google_MA_6\n",
    "Google_MA_6 <- SMA(Google_counts_market,6)\n",
    "\n",
    "#Get Google_Move\n",
    "Google_Move <- diff(Google_counts_market)  #Get the difference as previous day\n",
    "Google_Move[Google_Move<0] <- 0       # 0 means going down\n",
    "Google_Move[Google_Move>0] <- 1       # 1 means going up\n",
    "Google_Move <- data.frame(Google_Move) # Transfer to data frame\n",
    "Google_Move <- rbind(\"N/A\",Google_Move) # Move down for one row\n",
    "\n",
    "#Get Google_3day_Disparity_Move\n",
    "Google_MA_3 <- SMA(Google_counts_market,3)\n",
    "Google_3day_Disparity <- Google_counts_market/Google_MA_3\n",
    "Google_3day_Disparity <- as.numeric(unlist(Google_3day_Disparity))\n",
    "\n",
    "Google_3day_Disparity_Move <- diff(Google_3day_Disparity)\n",
    "Google_3day_Disparity_Move[Google_3day_Disparity_Move <0] <- 0       # 0 means going down\n",
    "Google_3day_Disparity_Move[Google_3day_Disparity_Move >0] <- 1       # 1 means going up\n",
    "Google_3day_Disparity_Move <- data.frame(Google_3day_Disparity_Move)\n",
    "Google_3day_Disparity_Move <- rbind(\"N/A\",Google_3day_Disparity_Move) # Move down for one row\n",
    "\n",
    "#Get Google_RSI_Move\n",
    "Google_RSI <- RSI(Google_counts_market, maType = \"WMA\")\n",
    "\n",
    "Google_RSI_Move <- diff(Google_RSI)\n",
    "Google_RSI_Move[Google_RSI_Move<0] <- 0       # 0 means going down\n",
    "Google_RSI_Move[Google_RSI_Move>0] <- 1       # 1 means going up\n",
    "Google_RSI_Move <- data.frame(Google_RSI_Move)\n",
    "Google_RSI_Move <- rbind(\"N/A\",Google_RSI_Move) # Move down for one row\n",
    "\n",
    "\n",
    "Google_ROC <- ROC(Google_counts_market,n=5) * 100\n",
    "\n",
    "Google_ROC_Move <- diff(Google_ROC)\n",
    "Google_ROC_Move[Google_ROC_Move<0] <- 0       # 0 means going down\n",
    "Google_ROC_Move[Google_ROC_Move>0] <- 1       # 1 means going up\n",
    "Google_ROC_Move <- data.frame(Google_ROC_Move)\n",
    "Google_ROC_Move <- rbind(\"N/A\",Google_ROC_Move) # Move down for one row\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporary full data after Wiki and Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in data.frame(Google_EMA5_Move, Google_MA_6, Google_Move, Google_3day_Disparity_Move, : object 'Google_EMA5_Move' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in data.frame(Google_EMA5_Move, Google_MA_6, Google_Move, Google_3day_Disparity_Move, : object 'Google_EMA5_Move' not found\nTraceback:\n",
      "1. data.frame(Google_EMA5_Move, Google_MA_6, Google_Move, Google_3day_Disparity_Move, \n .     Google_RSI_Move, Google_ROC_Move)"
     ]
    }
   ],
   "source": [
    "# Dealing with the missing data point after wiki\n",
    "Google_data <- data.frame(Google_EMA5_Move,Google_MA_6,Google_Move,\n",
    "                          Google_3day_Disparity_Move,Google_RSI_Move,\n",
    "                          Google_ROC_Move)\n",
    "fulldata_temp <- cbind(fulldata_temp,Google_data)\n",
    "head(fulldata_temp,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalize the data\n",
    "##### Preparing data for Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata <- fulldata_temp[20:nrow(fulldata_temp),]\n",
    "move_cols <- sapply(fulldata, is.character)\n",
    "move_cols[[\"RSI Move\"]] <- TRUE\n",
    "move_cols[[\"Target\"]] <- TRUE\n",
    "move_data <- as.data.frame(sapply(fulldata[,move_cols], as.factor))\n",
    "move_col_names <- names(move_data)\n",
    "non_move_data <- fulldata[, -which(names(fulldata) %in% move_col_names)]\n",
    "fulldata <- cbind(non_move_data,move_data)\n",
    "\n",
    "Target <- fulldata$Target\n",
    "fulldata$Target <- NULL\n",
    "fulldata <- cbind(fulldata,Target)\n",
    "fulldata <- fulldata[,2:ncol(fulldata)]\n",
    "numRows = dim(fulldata)[1]\n",
    "lastday = fulldata[numRows, ] \n",
    "fulldata = fulldata[1:numRows-1, ]\n",
    "fulldata = fulldata[names(fulldata) %in% Input_vars]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write.csv(\"stock.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting\n",
    "##### Applying 2 algorithm \n",
    "###### 1. Decision Tree\n",
    "###### 2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decison Tree Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata=read.csv(\"stock.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "#install.packages(\"C50\")\n",
    "library(caret)\n",
    "library(C50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata$Target = as.factor(fulldata$Target)\n",
    "accuracy=c()\n",
    "for (i in 1:100){\n",
    "  #assign 80% of the data to the training set\n",
    "  train.index = createDataPartition(fulldata$Target,p=0.80,list = F)\n",
    "  train <- fulldata[train.index,]\n",
    "  test = fulldata[-train.index,]\n",
    "  #build model using training data\n",
    "  c50_model = C5.0(Target ~.,train,trials=100,rules=T)\n",
    "  #calculate accuracy on test data\n",
    "  c50predict = predict(c50_model,test[,-20],type=\"class\")\n",
    "  accuracy[i] <- mean(c50predict == test$Target)\n",
    "}\n",
    "a=mean(accuracy) \n",
    "b=sd(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.693076923076923"
      ],
      "text/latex": [
       "0.693076923076923"
      ],
      "text/markdown": [
       "0.693076923076923"
      ],
      "text/plain": [
       "[1] 0.6930769"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata=read.csv(\"stock.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign 80% of the data to the training set\n",
    "\n",
    "  fulldata[, \"train\"] <- ifelse(runif(nrow(fulldata)) < 0.8, 1, 0)\n",
    "  trainColNum <- grep(\"train\", names(fulldata))\n",
    "  trainset <- fulldata[fulldata$train == 1, -trainColNum]\n",
    "  testset <- fulldata[fulldata$train == 0, -trainColNum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=c()\n",
    "for (i in 1:100){\n",
    "  #assign 80% of the data to the training set\n",
    "  fulldata[, \"train\"] <- ifelse(runif(nrow(fulldata)) < 0.8, 1, 0)\n",
    "  trainColNum <- grep(\"train\", names(fulldata))\n",
    "  trainset <- fulldata[fulldata$train == 1, -trainColNum]\n",
    "  testset <- fulldata[fulldata$train == 0, -trainColNum]\n",
    "  #build model using training data\n",
    "  svm_model <- svm(Target~ ., data = trainset, \n",
    "                   type = \"C-classification\", kernel = \"linear\")\n",
    "  #calculate accuracy on test data\n",
    "  pred_test <- predict(svm_model, testset)\n",
    "  accuracy[i] <- mean(pred_test == testset$Target)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.74292226806145"
      ],
      "text/latex": [
       "0.74292226806145"
      ],
      "text/markdown": [
       "0.74292226806145"
      ],
      "text/plain": [
       "[1] 0.7429223"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Conclusion\n",
    "#### we got better accuracy with SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
